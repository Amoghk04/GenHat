[
  {
    "heading": "GenAI Lab Week 5",
    "content": "GenAI Lab Week 5",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "Amogh Kalasapura",
    "content": "Amogh Kalasapura",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "1MS22CS022",
    "content": "1MS22CS022",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "1.  Create a LangChain application that takes the name of an institution as input and extracts",
    "content": "1.  Create a LangChain application that takes the name of an institution as input and extracts",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "structured information from Wikipedia. Use Pydantic to define the schema for the desired output",
    "content": "structured information from Wikipedia. Use Pydantic to define the schema for the desired output",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "and implement a custom output parser to enforce the schema. Your task is to invoke the chain and",
    "content": "and implement a custom output parser to enforce the schema. Your task is to invoke the chain and",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "fetch results about the institution with the following details:",
    "content": "fetch results about the institution with the following details:",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "i. The founder of the institution",
    "content": "i. The founder of the institution",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "ii. The year it was founded",
    "content": "ii. The year it was founded",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "iii. The current branches of the institution",
    "content": "iii. The current branches of the institution",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "iv. The number of employees working in it",
    "content": "iv. The number of employees working in it",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "v. A concise 4-line summary of the institution",
    "content": "v. A concise 4-line summary of the institution \n \nCode: \n!pip install langchain langchain-core langchain-openai wikipedia pydantic \n!pip install openai  # For using OpenAI models with LangChain \n \n!pip install langchain cohere langchain-cohere",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "import os",
    "content": "import os \nfrom langchain import PromptTemplate, LLMChain \nfrom langchain_cohere import ChatCohere \nfrom langchain.schema import BaseOutputParser \nfrom pydantic import BaseModel, Field",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "import wikipedia",
    "content": "import wikipedia",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "import json",
    "content": "import json \nos.environ[\"COHERE_API_KEY\"] =\u201dAPI KEY\u201d \n \nclass InstitutionInfo(BaseModel): \n    founder: str = Field(description=\"The name(s) of the founder(s) of the institution.\") \n    year_founded: str = Field(description=\"The year the institution was founded.\") \n    branches: str = Field(description=\"The list or description of departments and streams the institue offers\") \n    number_of_employees: str = Field(description=\"Approximate number of employees working there.\") \n    summary: str = Field(description=\"A concise 4-line summary of the institution.\") \n \ntemplate = \"\"\" \nYou are an information extraction agent. \n \nExtract details about the institution from the Wikipedia text below and return ONLY a valid JSON object. \nDo not include any notes, explanations, or extra text \u2014 just the JSON. \n \nInstitution Name: {institution_name} \nWikipedia Content: {wiki_content} \n \nJSON fields to include: \n- founder \n- year_founded \n- branches (that is the streams offered by the Institute) \n- number_of_employees (approximation if there is no information) \n- summary (a concise 4-line description) \n\"\"\" \n \nprompt = PromptTemplate( \n    input_variables=[\"institution_name\", \"wiki_content\"], \n    template=template \n) \ndef get_wikipedia_content(institution_name): \n\n    try: \n        page = wikipedia.page(institution_name, auto_suggest=False) \n        return page.content[:5000]  # limit content to avoid context overflow \n    except Exception as e: \n        print(\" Error fetching Wikipedia:\", e) \n        return \"No data found.\" \nimport re, json \n \nclass InstitutionOutputParser(BaseOutputParser): \n    def parse(self, text: str) -> \"InstitutionInfo\": \n        try: \n            data = json.loads(text) \n        except json.JSONDecodeError: \n            match = re.search(r\"\\{.*\\}\", text, re.DOTALL) \n            if not match: \n                print(\u201c No JSON found in output.\") \n                print(\"Raw output:\\n\", text) \n                raise \n            json_str = match.group(0) \n            data = json.loads(json_str) \n \n        clean_data = {} \n        for field in InstitutionInfo.model_fields.keys(): \n            val = data.get(field, \"Not available\") \n            # Convert all types to string for schema compliance \n            if isinstance(val, (list, dict)): \n                val = \", \".join(map(str, val)) \n            elif not isinstance(val, str): \n                val = str(val) \n            clean_data[field] = val or \"Not available\" \n \n        return InstitutionInfo(**clean_data) \n \nllm = ChatCohere(model=\"command-a-03-2025\", temperature=0) \nparser = InstitutionOutputParser() \nchain = LLMChain(llm=llm, prompt=prompt, output_parser=parser) \n \ninstitution_name = \"Ramaiah Institute of Technology\" \nwiki_content = get_wikipedia_content(institution_name) \n \nprint(\" Fetching structured information from Wikipedia...\\n\") \n \nresult = chain.run(institution_name=institution_name, wiki_content=wiki_content) \n \nprint(\"\\nInstitution Details\") \nprint(\"------------------------------\") \nprint(f\"Founder(s): {result.founder}\") \nprint(f\"Year Founded: {result.year_founded}\") \nprint(f\"Branches: {result.branches}\") \nprint(f\"Number of Employees: {result.number_of_employees}\") \nprint(\"\\nSummary:\\n\", result.summary) \n \nOutput: \n \nFetching structured information from Wikipedia...",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 1
  },
  {
    "heading": "Institution Details",
    "content": "Institution Details \n------------------------------ \nFounder(s): M. S. Ramaiah \nYear Founded: 1962 \n\nBranches: Aerospace Engineering, Architecture, Artificial Intelligence and Data Science, Artificial \nIntelligence and Machine Learning, Biotechnology, Chemical Engineering, Chemistry, Civil Engineering, \nComputer Science and Engineering, Computer Science and Engineering (AI and ML), Computer Science \nand Engineering (Cybersecurity), Electronics and Communication Engineering, Electronics and \nInstrumentation Engineering, Electrical and Electronics Engineering, Electronics and Telecommunication \nEngineering, Humanities, Industrial Engineering and Management, Information Science and Engineering, \nMathematics, Master of Computer Applications, Management Studies (MBA), Mechanical Engineering, \nMedical Electronics, Physics \nNumber of Employees: 800 \n \nSummary: \n Ramaiah Institute of Technology (RIT), formerly M.S. Ramaiah Institute of Technology, is a private \nengineering college in Bengaluru, Karnataka, India., Founded in 1962 by M. S. Ramaiah, it is affiliated \nwith Visvesvaraya Technological University and offers a wide range of undergraduate and postgraduate \nprograms., RIT is known for its academic autonomy, industry collaborations, and student-led initiatives in \ntechnology and innovation., The institute has partnerships with organizations like ISRO and IBM, and \nhosts various student clubs and events, including IEEE and TEDx.",
    "pdf_name": "LAB5-Langchain.pdf",
    "page_number": 2
  },
  {
    "heading": "Parallel Image Filtering on Multicore CPUs: A Comparative Study of Serial",
    "content": "Parallel Image Filtering on Multicore CPUs: A Comparative Study of Serial",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "versus Multiprocessing Implementations",
    "content": "versus Multiprocessing Implementations",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "Amogh Kalasapura",
    "content": "Amogh Kalasapura",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "M S Ramaiah Institute Of",
    "content": "M S Ramaiah Institute Of \nTechnology, Student",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "Amit A M",
    "content": "Amit A M",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "M S Ramaiah Institute Of",
    "content": "M S Ramaiah Institute Of \nTechnology, Student",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "Ashutosh Kumar",
    "content": "Ashutosh Kumar",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "M S Ramaiah Institute Of",
    "content": "M S Ramaiah Institute Of \nTechnology, Student",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "Ankush Balse",
    "content": "Ankush Balse",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "M S Ramaiah Institute Of",
    "content": "M S Ramaiah Institute Of \nTechnology, Student",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "Dr Mallegowda M",
    "content": "Dr Mallegowda M",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "M S Ramaiah Institute of Technology",
    "content": "M S Ramaiah Institute of Technology",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "Professor",
    "content": "Professor \n \nAbstract - This paper presents a rigorous and comprehensive investigation into the performance \ncharacteristics of several fundamental image filtering algorithms\u2014specifically, Laplacian edge detection, \nSobel edge detection, Contrast Limited Adaptive Histogram Equalization (CLAHE), and Gaussian blur. \nThese algorithms were implemented in Python, utilizing both serial baseline versions and parallel variants \naccelerated via the built-in multiprocessing module]. The experimental evaluation, systematically \nconducted on a 16-core x86_64 Linux system, yielded substantial performance improvements. \nSpecifically, the computationally intensive Laplacian, Sobel, and CLAHE filters achieved peak speedups \nreaching up to ~5.4x. In contrast, the Gaussian blur filter exhibited a distinct performance crossover point, \ndemonstrating a benefit from parallelization only when employing computationally demanding, larger \nkernels, typically defined by a standard deviation (sigma) of sigma >= 20. The study meticulously \nvalidated the numerical equivalence (ensuring pixel-perfect output matching) across all parallel \nimplementations relative to their serial counterparts. Furthermore, we quantified key performance metrics \nincluding throughput (Theta), speedup (S), and efficiency (E), and conducted a detailed multi-thread \nscalability analysis using the Laplacian filter as a representative case study. The results conclusively \ndemonstrate that performance scaling is non-linear with respect to the allocated thread count, and \ncritically, that system context switching overhead and memory contention can lead to significant \nperformance degradation when the thread count exceeds the empirically determined optimal level.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "1. Introduction",
    "content": "1. Introduction",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "1.1 The Imperative for Parallel Image Processing",
    "content": "1.1 The Imperative for Parallel Image Processing \n \nImage processing pipelines form the backbone of modern computer vision systems, from real-time \nsurveillance and medical imaging to autonomous navigation. In these domains, high throughput and \nminimal latency are not merely desirable features but critical, non-negotiable system requirements. While \nthe underlying hardware\u2014the Central Processing Unit (CPU)\u2014has architecturally evolved to expose \nmassive parallelism through the integration of multiple processing cores, a substantial proportion of \nestablished image processing algorithm implementations remain fundamentally single-threaded. This \npersistent reliance on serial execution results in a severe underutilization of available hardware resources \nand creates significant performance bottlenecks, particularly when handling high-resolution or \nhigh-framerate data streams. [5]",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "1.2 Scope of the Study",
    "content": "1.2 Scope of the Study \n \nThis research addresses this gap by focusing on the parallelization and rigorous performance analysis of \nfour archetypal and widely deployed image filters, each representing different computational \ncharacteristics: \n\u25cf Laplacian Edge Detection [2]: A measure of the second spatial derivative of an image, typically \nimplemented using a small 3x3 kernel. It is computationally simple but highly amenable to \nparallelism. \n\u25cf Sobel Edge Detection [3]: A first-order gradient operator that computes the gradient magnitude \nfrom separate horizontal and vertical kernels. It is slightly more computationally intensive than \nthe Laplacian. \n\u25cf Contrast Limited Adaptive Histogram Equalization (CLAHE) [4]: A sophisticated technique \nfor local contrast enhancement, which involves partitioning the image into tiles, computing and \nclipping histograms for each tile, and performing bilinear interpolation. Its tile-based structure \ninherently supports coarse-grained parallelism. \n\u25cf Gaussian Blur [1]: A common filter for noise reduction and detail suppression, characterized by \na kernel size that scales with its standard deviation (sigma). Its computational cost grows \nnon-linearly with sigma, making the compute-to-overhead ratio a critical factor.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 2
  },
  {
    "heading": "1.3 Research Objectives",
    "content": "1.3 Research Objectives \n \nThe primary objectives of this comprehensive study are formalized through the following precise research \nquestions: \n1. Speedup Quantification: What is the maximum magnitude of speedup (S) that can be realized \nby adopting the multiprocessing approach relative to their established serial baselines across \ndifferent filtering techniques? \n2. Scalability Analysis: How do variations in the input image size and the inherent algorithmic \ncomplexity (e.g., small kernel vs. tile-based vs. large kernel) fundamentally influence the system's \nscalability and parallel efficiency? \n3. Thread Count Optimization: What is the quantitative relationship between the number of \nallocated worker threads (processes) and the resulting execution performance, and how does this \nrelationship inform the determination of an optimal thread count? \n4. Numerical Validation: Is the numerical accuracy and integrity of the image output maintained \nacross all parallel implementations, ensuring pixel-perfect output matching with the serial \ncounterparts?",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 2
  },
  {
    "heading": "2. Methodology",
    "content": "2. Methodology",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 2
  },
  {
    "heading": "2.1 Experimental Environment and Dataset",
    "content": "2.1 Experimental Environment and Dataset \n \nThe entirety of the experimental phase was conducted in a controlled environment to ensure \nreproducibility and reliability of measurements.System and Libraries \n\n \n \nThe testing platform provides a contemporary multi-core architecture suitable for benchmarking parallel \nworkloads. The use of Python, alongside optimized libraries like NumPy and SciPy, ensures that the \nmeasured parallel gains primarily reflect the benefits of concurrency rather than algorithmic optimization \nbias.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 2
  },
  {
    "heading": "Category",
    "content": "Category",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Details",
    "content": "Details",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Platform",
    "content": "Platform \nLinux, x86_64 Architecture",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "CPU Configuration",
    "content": "CPU Configuration",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "16 logical cores (8 physical cores with",
    "content": "16 logical cores (8 physical cores with \nHyper-Threading)",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Software Stack",
    "content": "Software Stack \nPython 3.11.7",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Libraries",
    "content": "Libraries \nNumPy, SciPy (for numerical operations), Pillow \n(for image I/O), Matplotlib (for visualization) \nTable 1: Software Specifications",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Image Dataset Selection",
    "content": "Image Dataset Selection \n \nThe evaluation utilized three distinct images, selected specifically for their significant variation in scale \nand resolution. This variance was critical for comprehensively assessing the dependence of parallel \nefficiency and overhead amortization on the problem size.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Image Name",
    "content": "Image Name \nSize (Pixels)",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Approximate MP",
    "content": "Approximate MP",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Rationale",
    "content": "Rationale",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Lenna",
    "content": "Lenna \n512x515 \n~0.26 MP",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Represents a typical",
    "content": "Represents a typical \nsmall image; used to",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "study overhead",
    "content": "study overhead \ndominance.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Glass Ball",
    "content": "Glass Ball \n4077x3203 \n~13.06 MP",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Represents a large",
    "content": "Represents a large \nimage; used to study",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "maximum achievable",
    "content": "maximum achievable \nspeedup.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Banana",
    "content": "Banana \n2791x3907 \n~10.90 MP",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Represents a large",
    "content": "Represents a large \nimage; used to \ncross-validate results",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "from the Glass Ball",
    "content": "from the Glass Ball \ndataset. \nTable 2: Dataset Specifications",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "2.2 Parallelization and Measurement Strategy",
    "content": "2.2 Parallelization and Measurement Strategy",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Parallel Implementation Details",
    "content": "Parallel Implementation Details \n \nAll parallel implementations leveraged Python\u2019s multiprocessing.Pool class. This mechanism spawns \nindependent worker processes, effectively circumventing the Global Interpreter Lock (GIL) and enabling \ntrue concurrent execution across multiple CPU cores, ideal for CPU-bound tasks like image filtering. The \nimage partitioning strategy was meticulously optimized for the computational profile of each individual \nfilter.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "Filter",
    "content": "Filter",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "Serial Baseline",
    "content": "Serial Baseline",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "Parallelization",
    "content": "Parallelization",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 3
  },
  {
    "heading": "Method",
    "content": "Method",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 2
  },
  {
    "heading": "Partitioning Strategy",
    "content": "Partitioning Strategy",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "Laplacian",
    "content": "Laplacian \n \nStraightforward s\u2026\n \nPython multiproc\u2026\nGrid partitioning with \na 1-pixel halo region",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "for boundary handling",
    "content": "for boundary handling",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "between concurrent",
    "content": "between concurrent \ntiles.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "Sobel",
    "content": "Sobel \n \nStraightforward s\u2026\n \nPython multiproc\u2026\nRow-based \npartitioning with",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "explicit boundary",
    "content": "explicit boundary",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "handling for gradient",
    "content": "handling for gradient",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "computation across row",
    "content": "computation across row \nsplits.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "CLAHE",
    "content": "CLAHE \n \nStandard serial i\u2026\n \nPython multiproc\u2026",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "Independent tile",
    "content": "Independent tile \nprocessing where each \ntile's histogram",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "computation and clip",
    "content": "computation and clip",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "limiting are",
    "content": "limiting are \nparallelized;",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "interpolation is",
    "content": "interpolation is \nmanaged post-parallel \nexecution.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "Gaussian Blur",
    "content": "Gaussian Blur \n \nStandard serial i\u2026\n \nPython multiproc\u2026\nGrid-based splitting.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "The parallel benefit is",
    "content": "The parallel benefit is",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "expected to increase",
    "content": "expected to increase",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "proportionally with the",
    "content": "proportionally with the \nkernel size (sigma), as",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "the required",
    "content": "the required",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "computation per pixel",
    "content": "computation per pixel \ngrows. \nTable 3: Details of parallel implementation",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "Performance Metrics",
    "content": "Performance Metrics \n\n \nPerformance was quantitatively evaluated using standard, rigorous metrics derived from parallel \ncomputing theory. All measurements were averaged over three independent trials after a warm-up run to \nmitigate initial system noise.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "Metric",
    "content": "Metric",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 4
  },
  {
    "heading": "Formula",
    "content": "Formula",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 5
  },
  {
    "heading": "Description",
    "content": "Description \nSpeedup (S) \nS = T_{serial} / T_{parallel}",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 5
  },
  {
    "heading": "The ratio quantifying the",
    "content": "The ratio quantifying the",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 5
  },
  {
    "heading": "reduction in execution time",
    "content": "reduction in execution time \nachieved by parallelization. \nEfficiency (E) \nE = (S / N) x 100%",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 5
  },
  {
    "heading": "The measure of how effectively",
    "content": "The measure of how effectively",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 5
  },
  {
    "heading": "the parallelization utilizes the",
    "content": "the parallelization utilizes the",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 2
  },
  {
    "heading": "available N logical cores",
    "content": "available N logical cores \n(expressed as a percentage). \nThroughput (Theta) \nTheta = Pixels / T (MP/s)",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 5
  },
  {
    "heading": "The rate at which the system",
    "content": "The rate at which the system \nprocesses image data, measured \nin Millions of Pixels per second. \nTime Saved (Delta T) \nDelta T = T_{serial} - \nT_{parallel}",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 5
  },
  {
    "heading": "The absolute reduction in",
    "content": "The absolute reduction in \nprocessing time, crucial for \nreal-time applications. \nTable 4: Metrics",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 5
  },
  {
    "heading": "Accuracy Validation and Equivalence",
    "content": "Accuracy Validation and Equivalence \n \nA critical prerequisite for any parallel implementation is the verification of numerical correctness. \nAccuracy was validated by performing a pixel-level comparison (analyzing the maximum and mean \nabsolute difference) between the output of the parallel version and the output of the trusted serial baseline.  \nObservation: All parallel implementations were conclusively confirmed to be numerically equivalent to \ntheir serial counterparts, yielding zero observable differences, confirming the correctness of the \npartitioning and merging strategies.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 5
  },
  {
    "heading": "2.3 Multi-Thread Scalability Study (Laplacian Filter)",
    "content": "2.3 Multi-Thread Scalability Study (Laplacian Filter) \n \nTo precisely characterize the impact of thread count (N) on performance, a dedicated scalability study was \nexecuted using the Laplacian filter. This filter was chosen due to its high parallel potential and relatively \nfixed, low computational complexity (O(1) per pixel). The thread counts tested were {2, 4, 8, 16, 24, 32}, \nspanning sub-optimal, optimal (equal to core count), and over-saturated levels. \n \nObservation: The results clearly showed that optimal performance was consistently achieved at or \nslightly below the number of available logical cores (N=16). Performance was observed to degrade \nsignificantly when the system was over-saturated (e.g., N=24 or N=32), providing empirical evidence that \ncontext switching and resource contention become dominant overheads beyond the optimal point.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 5
  },
  {
    "heading": "3. Results and Discussion",
    "content": "3. Results and Discussion",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "3.1 Overall Performance Analysis",
    "content": "3.1 Overall Performance Analysis \n \nThe parallel implementations delivered significant and pragmatic speedups, validating the benefits of \nutilizing multi-core architectures for image filtering tasks, especially those involving large images.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "Filter",
    "content": "Filter",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 1
  },
  {
    "heading": "Observed Speedup",
    "content": "Observed Speedup",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "Range",
    "content": "Range \nTypical Efficiency (at \nOptimal N)",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "Key Observation and",
    "content": "Key Observation and",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "Computational Profile",
    "content": "Computational Profile",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "Laplacian",
    "content": "Laplacian \n~2.2x (small) to ~5.4x \n(large) \n \n14-34%\nHigh parallel potential.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "Efficiency loss",
    "content": "Efficiency loss",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "primarily attributed to",
    "content": "primarily attributed to \nprocess creation/joining \nand inter-process",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "communication",
    "content": "communication \noverhead.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "Sobel",
    "content": "Sobel \nHighest average ~4.7x \n \nN/A",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "Demonstrates strong",
    "content": "Demonstrates strong \ngains, benefiting from",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "its moderate",
    "content": "its moderate",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "computational intensity",
    "content": "computational intensity",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "which better amortizes",
    "content": "which better amortizes \nthe parallel overhead.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "CLAHE",
    "content": "CLAHE \nAverage ~4.6x \n \nN/A",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "Highly effective",
    "content": "Highly effective \ntile-parallelism. The",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "dominant parallelizable",
    "content": "dominant parallelizable",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "step is the histogram",
    "content": "step is the histogram \ncomputation/clipping.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "Gaussian Blur",
    "content": "Gaussian Blur \n~1.4x (at sigma >= 20) \n \nN/A",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "Requires a high",
    "content": "Requires a high \ncompute-to-overhead \nratio. Parallel overhead",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "dominates for small",
    "content": "dominates for small \nsigma, where",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "computation is",
    "content": "computation is \nminimal. \nTable 5: Performance analysis \n \n \n \n \n \n\n \n \n \n \nResult Images: \n \n \n(a) \n \n(b) \n \n(c) \n \n(d) \n \nFigure 1: (a) Laplacian filter (b) Gaussian Blur filter (c) CLAHE (d) Sobel filter comparisons of serial",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 6
  },
  {
    "heading": "parallel images",
    "content": "parallel images \n \n \n(a) \n \n(b) \n\n \n(c) \n \n(d) \nFigure 2: Time comparison of serial and parallel in (a) Laplacian filter (b) Gaussian Blur (c) CLAHE (d)",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 7
  },
  {
    "heading": "Sobel Filter",
    "content": "Sobel Filter",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 8
  },
  {
    "heading": "3.2 Throughput and Time Savings Highlights",
    "content": "3.2 Throughput and Time Savings Highlights \n \nThe ability to process millions of pixels per second (throughput) dramatically improved for the \nparallelized filters on large-scale data: \n\u25cf Large Images (>= ~10 MP): These datasets consistently exhibited the most significant benefits, \nwith throughput improvements ranging from ~3.5x to 5.5x for the Laplacian and Sobel filters. \n\u25cf CLAHE Performance: The highly parallelizable nature of CLAHE's internal tile processing \nenabled significant Delta T savings, confirming that algorithms defined by large, independent \ntasks are highly suitable for multiprocessing acceleration. \n\u25cf Gaussian Blur Threshold: The results established an empirical threshold: parallelizing Gaussian \nblur is only beneficial when the kernel size is large enough (i.e., sigma >= 20 in this study) that \nthe computational load outweighs the fixed costs of process management and data \nsplitting/joining.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 8
  },
  {
    "heading": "3.3 Multi-Thread Scalability and Optimization",
    "content": "3.3 Multi-Thread Scalability and Optimization \n \nThe scalability study revealed that while utilizing more threads initially provides benefits, diminishing \nreturns quickly set in, followed by performance degradation. \n\u25cf Lenna (Small Image) Scalability : The optimal thread count was observed at ~ 8 threads (half \nthe logical cores). Beyond this, the relative cost of overhead (process startup, synchronization) \nquickly outweighs the minimal computational gain from splitting the small workload further, \nleading to clear performance degradation beyond 16 threads. \n\n \nFigure 3: Laplacian Scalability\u2014Lenna  \n\u25cf Glass Ball (Large Image) Scalability: This large workload demonstrated the best utilization of \nresources, with the optimal performance achieved at ~ 16 threads. The large size effectively \namortized the overheads, enabling peak efficiency at full system capacity. \n \nFigure 4: Laplacian Scalability\u2014Glass Ball \n\u25cf Banana (Large Image) Scalability: This dataset showed an optimal point at ~ 8 threads, with \nnon-monotonic behavior observed at higher counts. This variability suggests that system-level \nfactors (e.g., operating system scheduling, memory access patterns) become increasingly \ninfluential as the system nears saturation. \n\n \nFigure 5: Laplacian Scalability\u2014Banana",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 8
  },
  {
    "heading": "Interpretation of Scalability",
    "content": "Interpretation of Scalability \n1. Non-linear Scaling: The observed relationship confirmed Amdahl's Law; the speedup gained \nfrom parallelization is limited by the serial fraction of the execution time (I/O, final merge, \nsetup). \n2. Overhead Amortization: The optimal thread count is dynamically linked to problem size. Larger \nimages provide a higher computational intensity per worker, allowing the fixed parallel overheads \nto be better amortized, thus permitting the use of more workers. \n3. Context Switching Penalty: Performance drop-off beyond the optimal thread count is a direct \nconsequence of thread over-saturation. The time spent by the operating system managing \nexcessive context switches, coupled with the frequent invalidation of local CPU caches \n(Cache/TLB effects), begins to consume more time than the computational work being \nperformed, halting scalability.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 10
  },
  {
    "heading": "4. Conclusion and Future Work",
    "content": "4. Conclusion and Future Work \n \nThis study has systematically evaluated the performance trade-offs inherent in migrating fundamental \nimage filtering algorithms from serial execution to a true multiprocessing paradigm on a modern \nmulti-core CPU. We have conclusively demonstrated that for computationally significant tasks like \nLaplacian, Sobel, and CLAHE, the adoption of parallel processing yields substantial, pragmatic speedups \n(typically ~4x to ~5x), while rigorously upholding pixel-perfect numerical accuracy. The specific case of \nthe Gaussian blur filter highlighted a critical dependency on the compute-to-overhead ratio, demonstrating \nthat parallel benefits are contingent upon a sufficiently large kernel size (sigma >= 20). \n \nThe multi-thread scalability analysis for the Laplacian filter provided critical insights into the \nperformance ceiling of CPU-based parallelism. It conclusively proved that performance is ultimately \nlimited by system overheads\u2014specifically context switching and memory locality issues\u2014when the \nthread count exceeds the empirically determined optimal level. Critically, we established that larger image \nworkloads are inherently more robust against these overheads, allowing for the effective deployment of a \nhigher degree of parallelism. \n\n \nThe collective findings underscore the necessity of moving beyond simple maximal threading \nassumptions. A pragmatic, measurement-driven approach is required: thread counts must be carefully \ntuned based on the specific workload's size and the algorithm's complexity. The methodology and analysis \npresented here offer a robust, reproducible foundation. \n \nReferences:",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 10
  },
  {
    "heading": "1. Investigation on the effect of a Gaussian Blur in image filtering and segmentation, Jan 2011, et.al",
    "content": "1. Investigation on the effect of a Gaussian Blur in image filtering and segmentation, Jan 2011, et.al",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 11
  },
  {
    "heading": "Estevao Gedraite",
    "content": "Estevao Gedraite",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 11
  },
  {
    "heading": "2. Fast local Laplacian filters: Theory and applications et.al Aubry, M., Paris, S., Hasinoff, S.W.,",
    "content": "2. Fast local Laplacian filters: Theory and applications et.al Aubry, M., Paris, S., Hasinoff, S.W., \nKautz, J., and Durand, F., ACM Transactions on Graphics, 2014",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 11
  },
  {
    "heading": "3. Kanopoulos, N., Vasanthavada, N., & Baker, R. L. (1988). Design of an image edge detection",
    "content": "3. Kanopoulos, N., Vasanthavada, N., & Baker, R. L. (1988). Design of an image edge detection \nfilter using the Sobel operator. IEEE Journal of Solid-State Circuits, 23(2)",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 11
  },
  {
    "heading": "4. Adaptive Histogram Equalization and Its Variations, by S. M. Pizer, E. P. Amburn, J. D. Austin,",
    "content": "4. Adaptive Histogram Equalization and Its Variations, by S. M. Pizer, E. P. Amburn, J. D. Austin,",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 11
  },
  {
    "heading": "R. Cromartie, A. Geselowitz, T. Greer, B. M. ter Haar Romeny, J. B. Zimmerman, and K.",
    "content": "R. Cromartie, A. Geselowitz, T. Greer, B. M. ter Haar Romeny, J. B. Zimmerman, and K. \nZuiderveld, Computer Vision, Graphics, and Image Processing, vol. 39, pp. 355\u2013368, 1987.",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 11
  },
  {
    "heading": "5. General-Purpose",
    "content": "5. General-Purpose",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 11
  },
  {
    "heading": "Multicore",
    "content": "Multicore \nArchitectures,",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 11
  },
  {
    "heading": "Saugata",
    "content": "Saugata \nGhose,",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 11
  },
  {
    "heading": "University",
    "content": "University \nof",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 11
  },
  {
    "heading": "Illinois",
    "content": "Illinois \nUrbana-Champaign, arXiv:2408.12999v1 [cs.AR] 23 Aug 2024",
    "pdf_name": "MAP-Research-Paper.pdf",
    "page_number": 11
  },
  {
    "heading": "GenAI Lab 6",
    "content": "GenAI Lab 6",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "Name: Amogh Kalasapura",
    "content": "Name: Amogh Kalasapura",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "USN: 1MS22CS022",
    "content": "USN: 1MS22CS022 \n \nQuestion: Download the official Indian Penal Code (IPC) document in text or PDF format. Using LangChain (or a \nsimilar framework) and a language model of your choice (e.g., Cohere, OpenAI, or Hugging Face models), build a \nchatbot that can interact with the IPC. The chatbot should allow users to ask questions about specific sections, laws, \nor provisions, and provide relevant answers. \nImplement the following steps:",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "i. Load and preprocess the IPC document (text extraction if PDF).",
    "content": "i. Load and preprocess the IPC document (text extraction if PDF).",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "ii. Split the document into smaller chunks for efficient retrieval.",
    "content": "ii. Split the document into smaller chunks for efficient retrieval.",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "iii. Create an embedding-based vector store to enable semantic search.",
    "content": "iii. Create an embedding-based vector store to enable semantic search.",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "iv. Integrate a retrieval-based QA pipeline with a language model.",
    "content": "iv. Integrate a retrieval-based QA pipeline with a language model.",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "v. Deploy a chatbot interface where users can query the IPC.",
    "content": "v. Deploy a chatbot interface where users can query the IPC.",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "Code:",
    "content": "Code: \nimport os \nfrom langchain_cohere import ChatCohere, CohereEmbeddings \nfrom langchain_community.vectorstores import FAISS \nfrom langchain.text_splitter import RecursiveCharacterTextSplitter \nfrom langchain.chains import RetrievalQA \nfrom langchain.document_loaders import PyPDFLoader \n# Set your API key \nos.environ[\"COHERE_API_KEY\"] = \"KEY\" \nloader = PyPDFLoader(\"/content/IPC_186045.pdf\") \ndocs = loader.load() \nprint(f\"Total pages loaded: {len(docs)}\") \nsplitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=100) \nchunks = splitter.split_documents(docs) \nprint(f\"Total chunks created: {len(chunks)}\") \nchunks = chunks[:20] \nembeddings = CohereEmbeddings(model=\"embed-english-v3.0\") \nvectorstore = FAISS.from_documents(chunks, embeddings) \nretriever = vectorstore.as_retriever() \nllm = ChatCohere(model=\"command-a-03-2025\") \nqa_chain = RetrievalQA.from_chain_type( \n   llm=llm, \n   retriever=retriever, \n   chain_type=\"stuff\" \n) \nprint(\"IPC Chatbot ready! Type 'exit' to stop.\\n\") \nwhile True: \n   query = input(\"You: \") \n   if query.lower() == \"exit\": \n       break \n   response = qa_chain.run(query) \n   print(f\"Bot: {response}\\n\") \ndef chat_with_ipc(message, history): \n   if not message: \n       return history, history \n\n   # Get model response \n   response = qa_chain.run(message) \n   # Append to chat history (OpenAI-style format) \n   history.append({\"role\": \"user\", \"content\": message}) \n   history.append({\"role\": \"assistant\", \"content\": response}) \n   return history, history \nwith gr.Blocks() as demo: \n   gr.Markdown(\"## \u2696 IPC Chatbot \u2014 Ask questions about the Indian Penal Code\") \n   chatbot = gr.Chatbot(type=\"messages\", height=400) \n   msg = gr.Textbox( \n       placeholder=\"Type your question about IPC and press Enter...\", \n       label=\"Your Question\" \n   ) \n   state = gr.State([]) \n   # Submit message \n   msg.submit(chat_with_ipc, [msg, state], [chatbot, state]) \n   msg.submit(lambda: \"\", None, msg)  # clear the input box after sending \ndemo.launch(share=True)",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "Output:",
    "content": "Output: \nYou: what is the IPC 156 \n \nBot: The information provided does not contain any details about IPC 156. \nThe sections mentioned in the context are from the Indian Penal Code (IPC) \nbut do not include Section 156.",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 2
  },
  {
    "heading": "Section 156 of the IPC is related to the liability of a person for an act",
    "content": "Section 156 of the IPC is related to the liability of a person for an act \ndone by another person. It states:",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 2
  },
  {
    "heading": "Section 156. Liability of agent of owner, or person in charge, of a ship,",
    "content": "Section 156. Liability of agent of owner, or person in charge, of a ship, \nor of a horse, elephant or other animal, or of a machinery.",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 2
  },
  {
    "heading": "When an act is abetted by the agent of the owner, or by the person in",
    "content": "When an act is abetted by the agent of the owner, or by the person in \ncharge, of a ship, or of a horse, elephant or other animal, or of any \nmachinery, and the act is done by the owner or by any person using or \nmanaging the ship, animal or machinery, with the knowledge and without the \ndissent of such agent, the owner or other person using or managing the \nship, animal or machinery, and not the agent, is deemed to have done the \nact.",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 2
  },
  {
    "heading": "GenAI Lab Week - 7",
    "content": "GenAI Lab Week - 7",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 3
  },
  {
    "heading": "Name: Amogh Kalasapura",
    "content": "Name: Amogh Kalasapura",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "USN: 1MS22CS022",
    "content": "USN: 1MS22CS022",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "Question:",
    "content": "Question: \nWrite a PyTorch program that performs time series forecasting using an RNN. The program \nshould complete the following steps: \n \ni. \nGenerate synthetic time series data using a sine function with added noise and visualize \nthe data using matplotlib. \nii. \nPrepare the dataset by creating input\u2013output pairs using a fixed time step window \n(sequence length). \niii. \nDefine an RNN model using PyTorch, including: a recurrent layer (nn.RNN) a fully \nconnected layer (nn.Linear) for prediction. \niv. \nTrain the model using the Mean Squared Error (MSE) loss function and the Adam \noptimizer. Use the trained model to make predictions on the time series data. \nv. \nPrint the loss value during training to monitor progress. \nvi. \nVisualize the original time series data along with the predicted values to assess the \nmodel\u2019s performance.",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 3
  },
  {
    "heading": "Code:",
    "content": "Code:",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "import numpy as np",
    "content": "import numpy as np \nimport matplotlib.pyplot as plt \nimport torch \nimport torch.nn as nn \nfrom torch.utils.data import Dataset, DataLoader \nnp.random.seed(42) \nT = 500 \ntime = np.arange(0, T) \ndata = np.sin(0.02 * time) + 0.3 * np.random.randn(T) \nplt.figure(figsize=(10, 4)) \nplt.plot(time, data, label=\"Time Series Data\") \nplt.title(\"Synthetic Time Series (Sine + Noise)\") \nplt.legend() \nplt.show() \nSEQ_LEN = 20 \ndef create_sequences(data, seq_len): \n   xs, ys = [], [] \n   for i in range(len(data) - seq_len): \n       x = data[i:i + seq_len] \n       y = data[i + seq_len] \n       xs.append(x) \n       ys.append(y) \n   return np.array(xs), np.array(ys) \nX, y = create_sequences(data, SEQ_LEN) \nX = torch.tensor(X, dtype=torch.float32).unsqueeze(-1) \ny = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)  \nclass TimeSeriesDataset(Dataset): \n   def __init__(self, X, y): \n       self.X = X \n\n       self.y = y \n   def __len__(self): \n       return len(self.X) \n   def __getitem__(self, idx): \n       return self.X[idx], self.y[idx] \ndataset = TimeSeriesDataset(X, y) \nloader = DataLoader(dataset, batch_size=32, shuffle=True) \nclass RNNForecaster(nn.Module): \n   def __init__(self, input_size=1, hidden_size=32, num_layers=1): \n       super().__init__() \n       self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True) \n       self.fc = nn.Linear(hidden_size, 1) \n   def forward(self, x): \n       out, _ = self.rnn(x) \n       out = out[:, -1, :]  # last time step \n       out = self.fc(out) \n       return out \nmodel = RNNForecaster() \ncriterion = nn.MSELoss() \noptimizer = torch.optim.Adam(model.parameters(), lr=0.01) \nEPOCHS = 40 \nfor epoch in range(EPOCHS): \n   for batch_x, batch_y in loader: \n       optimizer.zero_grad() \n       preds = model(batch_x) \n       loss = criterion(preds, batch_y) \n       loss.backward() \n       optimizer.step() \n   print(f\"Epoch {epoch+1}/{EPOCHS}, Loss = {loss.item():.6f}\") \nmodel.eval() \nwith torch.no_grad(): \n   predictions = model(X).numpy() \nplt.figure(figsize=(12, 5)) \nplt.plot(time, data, label=\"Original Data\") \nplt.plot(time[SEQ_LEN:], predictions, label=\"RNN Predictions\") \nplt.title(\"RNN Time Series Forecasting\") \nplt.legend() \nplt.show()",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 3
  },
  {
    "heading": "Output:",
    "content": "Output: \n\n \n \nEpoch 1/40, Loss = 0.089657 \nEpoch 2/40, Loss = 0.141020 \nEpoch 3/40, Loss = 0.107610 \nEpoch 4/40, Loss = 0.065374 \nEpoch 5/40, Loss = 0.073423 \nEpoch 6/40, Loss = 0.067688 \nEpoch 7/40, Loss = 0.088336 \nEpoch 8/40, Loss = 0.100625 \nEpoch 9/40, Loss = 0.069667 \nEpoch 10/40, Loss = 0.128344 \nEpoch 11/40, Loss = 0.117956 \nEpoch 12/40, Loss = 0.140901 \nEpoch 13/40, Loss = 0.165409 \nEpoch 14/40, Loss = 0.124007 \nEpoch 15/40, Loss = 0.133383 \nEpoch 16/40, Loss = 0.132999 \nEpoch 17/40, Loss = 0.136760 \nEpoch 18/40, Loss = 0.129319 \nEpoch 19/40, Loss = 0.108026 \nEpoch 20/40, Loss = 0.078391 \nEpoch 21/40, Loss = 0.073528 \nEpoch 22/40, Loss = 0.125008 \nEpoch 23/40, Loss = 0.109070 \nEpoch 24/40, Loss = 0.133100 \nEpoch 25/40, Loss = 0.175448 \nEpoch 26/40, Loss = 0.201732 \nEpoch 27/40, Loss = 0.091373 \nEpoch 28/40, Loss = 0.093650 \nEpoch 29/40, Loss = 0.124441 \nEpoch 30/40, Loss = 0.119056 \nEpoch 31/40, Loss = 0.140938 \nEpoch 32/40, Loss = 0.138271 \nEpoch 33/40, Loss = 0.145478 \nEpoch 34/40, Loss = 0.159028 \nEpoch 35/40, Loss = 0.084976 \nEpoch 36/40, Loss = 0.095577 \nEpoch 37/40, Loss = 0.138798 \nEpoch 38/40, Loss = 0.173529 \nEpoch 39/40, Loss = 0.114366 \nEpoch 40/40, Loss = 0.079831",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "Question:",
    "content": "Question: \n\nBuild and train an LSTM-based text generation model using a dataset of your choice (e.g., \nShakespeare\u2019s plays, song lyrics, or news articles). Preprocess the text into sequences, train the \nLSTM to predict the next character or word, and then generate new text by providing a starting \nseed phrase. Experiment with hyper-parameters such as sequence length, number of LSTM \nunits, and training epochs.",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "Code:",
    "content": "Code:",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 1
  },
  {
    "heading": "import tensorflow as tf",
    "content": "import tensorflow as tf",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 6
  },
  {
    "heading": "import numpy as np",
    "content": "import numpy as np \nfrom google.colab import files \n \nprint(\"TensorFlow Version:\", tf.__version__) \nurl \n= \n\"https://gist.githubusercontent.com/blakesanie/dde3a2b7e698f52f389532b4b52bc254/raw/76fe1b5e9efcf0d2afdfd78b0bfaa737ad0a67d3/shakes\npeare.txt\" \nfile_path = tf.keras.utils.get_file(\"shakespeare_linked.txt\", origin=url) \nprint(\"Downloaded dataset to:\", file_path) \n \nwith open(file_path, \"r\", encoding=\"utf-8\") as f: \n    text = f.read() \ntext = text[:500000] \nprint(\"Dataset length:\", len(text)) \nvocab = sorted(set(text)) \nchar2idx = {c:i for i, c in enumerate(vocab)} \nidx2char = np.array(vocab) \nencoded_text = np.array([char2idx[c] for c in text]) \n \nprint(\"Vocabulary size:\", len(vocab)) \nSEQ_LENGTH = 100    # try 50, 100, 150 \nBATCH_SIZE = 64 \nBUFFER_SIZE = 10000 \ndef create_sequences(text_array, seq_length): \n    x, y = [], [] \n    for i in range(len(text_array) - seq_length): \n        x.append(text_array[i : i + seq_length]) \n        y.append(text_array[i + seq_length]) \n    return np.array(X), np.array(y) \n \nx, y = create_sequences(encoded_text, SEQ_LENGTH) \nprint(\"Total sequences created:\", x.shape[0]) \n \ndataset = tf.data.Dataset.from_tensor_slices((X, y)) \ndataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True) \nLSTM_UNITS = 512   # you can try 128, 256, 512 \nembedding_dim = 256 \n \nmodel = tf.keras.Sequential([ \n    tf.keras.layers.Embedding( \n        input_dim=len(vocab), \n        output_dim=embedding_dim, \n        input_length=SEQ_LENGTH \n    ), \n    tf.keras.layers.LSTM(LSTM_UNITS, return_sequences=True), \n    tf.keras.layers.LSTM(LSTM_UNITS), \n    tf.keras.layers.Dense(len(vocab), activation=\"softmax\") \n]) \n\n \n \nmodel.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\") \nmodel.build(input_shape=(None, SEQ_LENGTH)) \nmodel.summary() \nEPOCHS = 10   # you can try 10, 20, 40 \nhistory = model.fit(dataset, epochs=EPOCHS) \ndef generate_text(model, seed_text, gen_length=500, temperature=1.0): \n    input_indices = [char2idx[c] for c in seed_text] \n    input_indices = np.expand_dims(input_indices, 0) \n    generated = [] \n \n    for _ in range(gen_length): \n        predictions = model.predict(input_indices, verbose=0)[0] \n        predictions = predictions.astype(\"float64\") \n        # apply temperature \n        predictions = np.log(predictions + 1e-9) / temperature \n        exp_preds = np.exp(predictions) \n        predictions = exp_preds / np.sum(exp_preds) \n        next_index = np.random.choice(len(vocab), p=predictions) \n        next_char = idx2char[next_index] \n        generated.append(next_char) \n        # shift input \n        input_indices = np.append(input_indices[:,1:], [[next_index]], axis=1) \n \n    return seed_text + \"\".join(generated) \nseed_phrase = \"ROMEO: \" \nprint(\"\\n=== GENERATED TEXT ===\\n\") \nprint(generate_text(model, seed_text=seed_phrase, gen_length=600, temperature=0.8))",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 3
  },
  {
    "heading": "Output:",
    "content": "Output: \n \n=== GENERATED TEXT === \n \nROMEO: but \n    That \n          \" \n       \"This common's \n        \"The Earth, \n    And to hang in crown'd born, \n        Exit Hower is. How from me. I say; were in exile \n    Moving on a little remedy. \n  TOUCH OF SOLiDE \nDI SIED OF kill I take alone. \n  ORLANDO, my neck; \n        \" \n  ROSALIND. PROCULEIS and I speak the. If th' world to \n           \"                        SrARUs, a traitor, but I think. \n \n       \"     meety be. Let me too \n    Apbition of action, \n    As that dostends. \n  JAQUES \nhouth. I know, \n    And, something in Athen to me \n    The exile. Come not \n    'Twixt you see what he is. \n  ORLANDOON,",
    "pdf_name": "GenAI - Final Lab.pdf",
    "page_number": 7
  },
  {
    "heading": "Output -",
    "content": "Output - \n \nAbsolutely! Here\u2019s a short, engaging blog post on why time management is important:",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 1
  },
  {
    "heading": "Why Time Management is Your Secret Superpower",
    "content": "Why Time Management is Your Secret Superpower \nEver feel like there just aren\u2019t enough hours in the day? You\u2019re not alone. Whether it\u2019s \njuggling work deadlines, family commitments, or personal goals, managing time effectively \ncan feel like a never-ending challenge. But here\u2019s the good news: mastering time \nmanagement isn\u2019t just for corporate gurus or productivity experts\u2014it\u2019s a game changer \nanyone can use to feel less stressed and get more done. \nTake Sarah, for example. She used to stay up late, scrambling to finish projects last minute \nand missing out on weekend plans. Her stress levels were through the roof, and she often \nfelt burned out. After she started organizing her tasks and setting realistic priorities, she \nfound she could finish work earlier, enjoy her evenings, and even pick up a hobby she\u2019d \nbeen putting off. That\u2019s the power of time management.",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 1
  },
  {
    "heading": "Why Does Time Management Matter?",
    "content": "Why Does Time Management Matter? \nFirst off, managing your time well reduces stress. When you know what needs to be done \nand have a plan, the overwhelm fades. Instead of reacting to deadlines, you proactively \nmanage your day. This helps you avoid the frantic, last-minute rush that leaves you \nexhausted. \nSecond, it boosts productivity. When you allocate time to important tasks without \ndistractions, you get more done in less time. Imagine completing your work in a focused \ntwo-hour block instead of dragging it out all day\u2014that\u2019s the magic of effective time \nmanagement. \nFinally, it improves your work-life balance. When you\u2019re efficient, you carve out more quality \ntime for yourself and your loved ones. This balance is crucial for overall happiness and \nlong-term success.",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 1
  },
  {
    "heading": "Simple Tips to Start Today",
    "content": "Simple Tips to Start Today \n1. Prioritize Your Tasks: Use a simple to-do list or a planner. Identify your top 3 tasks \neach day and tackle those first. This keeps you focused on what really matters. \n\n2. Set Time Blocks: Dedicate specific chunks of time to tasks, like checking emails for",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 1
  },
  {
    "heading": "30 minutes in the morning rather than constantly throughout the day. This minimizes",
    "content": "30 minutes in the morning rather than constantly throughout the day. This minimizes \ndistractions and keeps you in the zone. \n \nRemember, time management isn\u2019t about squeezing every minute out of your day\u2014it\u2019s about \nmaking your time work for you. Start small, be consistent, and watch how your days \ntransform.",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "2.Simulate a data science data science mock interview for practice",
    "content": "2.Simulate a data science data science mock interview for practice \nPrompt - Simulate a realistic data science mock interview for practice. Act as an \nexperienced interviewer from a top tech company. Include a mix of technical and behavioral \nquestions covering topics such as data analysis, statistics, machine learning, Python coding, \nSQL, and problem-solving. Start by asking one question at a time and wait for my response \nbefore continuing. After each answer, provide feedback and ask follow-up questions as \nneeded. Keep the tone professional but supportive, as in a real interview setting",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "Output -",
    "content": "Output -",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 1
  },
  {
    "heading": "Data Science Mock Interview Questions",
    "content": "Data Science Mock Interview Questions",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "Technical \u2013 Data Analysis & Statistics",
    "content": "Technical \u2013 Data Analysis & Statistics",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "1. You\u2019re given a dataset with both numerical and categorical features and a binary",
    "content": "1. You\u2019re given a dataset with both numerical and categorical features and a binary \ntarget variable. How would you approach feature selection and why?",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "2. Explain the difference between Type I and Type II errors in hypothesis testing. How",
    "content": "2. Explain the difference between Type I and Type II errors in hypothesis testing. How \ndo they affect decision-making in data analysis?",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "Technical \u2013 Machine Learning",
    "content": "Technical \u2013 Machine Learning",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "3. What is the bias-variance tradeoff? How would you detect if your model is overfitting",
    "content": "3. What is the bias-variance tradeoff? How would you detect if your model is overfitting \nor underfitting?",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "4. Describe how a random forest works. What are its advantages compared to a single",
    "content": "4. Describe how a random forest works. What are its advantages compared to a single \ndecision tree?",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "Technical \u2013 Python Coding",
    "content": "Technical \u2013 Python Coding",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "5. Write a Python function to compute the moving average of a list of numbers given a",
    "content": "5. Write a Python function to compute the moving average of a list of numbers given a \nwindow size k.",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "6. How would you handle missing data in a dataset using Python? Give specific",
    "content": "6. How would you handle missing data in a dataset using Python? Give specific \nexamples of libraries or functions you would use.",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "Technical \u2013 SQL",
    "content": "Technical \u2013 SQL",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "7. Write an SQL query to find the second highest salary from a table named",
    "content": "7. Write an SQL query to find the second highest salary from a table named \nEmployees with columns EmployeeID and Salary.",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "8. How would you optimize a slow-running SQL query?",
    "content": "8. How would you optimize a slow-running SQL query? \n \n\nProblem-Solving & Case Study",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 2
  },
  {
    "heading": "9. Imagine you are given a dataset of customer transactions for an e-commerce site,",
    "content": "9. Imagine you are given a dataset of customer transactions for an e-commerce site, \nand sales have dropped recently. How would you analyze the data to find potential \nreasons? What metrics or visualizations would you look at?",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 3
  },
  {
    "heading": "Behavioral",
    "content": "Behavioral",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 3
  },
  {
    "heading": "10. Tell me about a challenging data project you worked on. What obstacles did you face,",
    "content": "10. Tell me about a challenging data project you worked on. What obstacles did you face, \nand how did you overcome them?",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 3
  },
  {
    "heading": "11. Describe a situation where you had to explain a complex technical concept to a",
    "content": "11. Describe a situation where you had to explain a complex technical concept to a \nnon-technical stakeholder. How did you ensure they understood? \n \n3.Write a mail to your boss about salary increment \nPrompt - Write a professional and polite email to my boss requesting a salary increment. \nThe email should briefly highlight my recent achievements, contributions to the team or \ncompany, and the value I bring. Use a respectful tone, express gratitude for the opportunities \ngiven, and clearly state my request for a salary review. Keep the email concise and focused.",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 3
  },
  {
    "heading": "Output -",
    "content": "Output - \nCertainly! Here\u2019s a professional and polite email template for your salary increment request: \n \nSubject: Request for Salary Review \nDear [Boss\u2019s Name], \nI hope this message finds you well. I want to take a moment to express my gratitude for the \nopportunities and support you have provided me during my time at [Company Name]. It has \nbeen a rewarding experience contributing to the team\u2019s success. \nOver the past [time period], I have taken on additional responsibilities and successfully \n[briefly mention key achievements or projects, e.g., led the XYZ project to completion ahead \nof schedule, improved process efficiency by 15%, etc.]. I believe my contributions have \npositively impacted our team\u2019s goals and the company\u2019s overall performance. \nIn light of these accomplishments and the value I bring to the team, I would like to kindly \nrequest a review of my current salary. I am confident that an adjustment would reflect my \ncommitment and the results I have delivered. \nI would appreciate the opportunity to discuss this further at your convenience. Thank you \nvery much for your consideration. \nBest regards, \n Amogh Kalasapura \n4.Create a workout routine that can help me lose 12 pounds in two months without the",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 3
  },
  {
    "heading": "use of equipment",
    "content": "use of equipment \n\n \nPrompt - Create a detailed, equipment-free workout routine designed to help me lose 12 \npounds in two months. The plan should include a mix of cardio, strength, and flexibility \nexercises that can be done at home or anywhere without any gym equipment. Provide a \nweekly schedule with exercise types, durations, and intensity levels, along with tips on \nprogression and recovery. Also, include general advice on staying motivated and safe while \nworking out.",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 1
  },
  {
    "heading": "Output -",
    "content": "Output -  \nSure! Here\u2019s a detailed, equipment-free workout routine designed to help you lose 12 \npounds in two months. It combines cardio, strength, and flexibility exercises you can do \nanywhere. The plan balances intensity with recovery and includes tips for progression and \nmotivation. \n \n12-Week Equipment-Free Workout Plan to Lose 12 Pounds",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Weekly Schedule Overview",
    "content": "Weekly Schedule Overview \nDay",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Workout Type",
    "content": "Workout Type",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Duration",
    "content": "Duration",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Intensity",
    "content": "Intensity",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Monday",
    "content": "Monday \nCardio + Core",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "40 minutes",
    "content": "40 minutes",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Moderate to High",
    "content": "Moderate to High",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Tuesday",
    "content": "Tuesday",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Full Body Strength",
    "content": "Full Body Strength",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "45 minutes",
    "content": "45 minutes",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Moderate",
    "content": "Moderate",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Wednesday",
    "content": "Wednesday \nActive Recovery & Flexibility",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "30 minutes",
    "content": "30 minutes \nLow (Stretching/Yoga)",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Thursday",
    "content": "Thursday",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Cardio Intervals",
    "content": "Cardio Intervals",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "30 minutes",
    "content": "30 minutes \nHigh (HIIT style)",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Friday",
    "content": "Friday",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Lower Body Strength",
    "content": "Lower Body Strength",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "45 minutes",
    "content": "45 minutes",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Moderate",
    "content": "Moderate",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Saturday",
    "content": "Saturday",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Full Body Circuit",
    "content": "Full Body Circuit",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "50 minutes",
    "content": "50 minutes",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Moderate to High",
    "content": "Moderate to High",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Sunday",
    "content": "Sunday",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Rest or Gentle Yoga",
    "content": "Rest or Gentle Yoga \n20-30 minutes \nLow",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Daily Workout Details",
    "content": "Daily Workout Details \nMonday: Cardio + Core \n\u25cf Warm-up: 5 minutes brisk walking or jogging in place \n\u25cf Cardio: 25 minutes steady-state jogging, jumping jacks, or high knees \n\u25cf Core Circuit (repeat 3 times): \n\u25cb Plank \u2013 30 seconds \n\u25cb Bicycle crunches \u2013 20 reps \n\u25cb Leg raises \u2013 15 reps \n\u25cb Russian twists \u2013 20 reps (10 each side) \n\n\u25cf Cool-down: 5 minutes stretching focusing on abs and hips \nTuesday: Full Body Strength \n\u25cf Warm-up: 5 minutes dynamic stretching \n\u25cf Circuit (repeat 4 times, rest 60 seconds between rounds): \n\u25cb Push-ups \u2013 15 reps \n\u25cb Bodyweight squats \u2013 20 reps \n\u25cb Glute bridges \u2013 20 reps \n\u25cb Superman hold \u2013 30 seconds \n\u25cb Tricep dips (use a chair) \u2013 15 reps \n\u25cf Cool-down: 5 minutes stretching (focus on arms, legs, back) \nWednesday: Active Recovery & Flexibility \n\u25cf Gentle yoga or stretching session (focus on deep breathing and mobility) \n\u25cf Hold stretches for 20-30 seconds each, targeting hamstrings, quads, shoulders, \nback, and hips \nThursday: Cardio Intervals (HIIT) \n\u25cf Warm-up: 5 minutes walking/jogging in place \n\u25cf 30-second work / 30-second rest intervals (repeat 10 rounds): \n\u25cb Burpees \n\u25cb Mountain climbers \n\u25cb Jump squats \n\u25cb High knees \n\u25cb Jumping jacks \n\u25cf Cool-down: 5 minutes walking and stretching \nFriday: Lower Body Strength \n\u25cf Warm-up: 5 minutes dynamic leg swings and lunges \n\u25cf Circuit (repeat 4 times, rest 60 seconds): \n\u25cb Jump squats \u2013 15 reps \n\u25cb Forward lunges \u2013 12 reps each leg \n\u25cb Wall sit \u2013 45 seconds \n\u25cb Calf raises \u2013 25 reps \n\u25cb Glute bridges \u2013 20 reps \n\u25cf Cool-down: Stretch legs and lower back \nSaturday: Full Body Circuit \n\u25cf Warm-up: 5 minutes light jogging or jumping jacks \n\u25cf Circuit (repeat 4 times): \n\u25cb Push-ups \u2013 15 reps \n\u25cb Squat to calf raise \u2013 20 reps \n\u25cb Plank with shoulder taps \u2013 30 seconds \n\u25cb Walking lunges \u2013 12 reps each leg \n\n\u25cb Superman hold \u2013 30 seconds \n\u25cf Cool-down: Stretch all major muscle groups \nSunday: Rest or Gentle Yoga \n\u25cf Focus on full-body stretching or gentle yoga flow \n\u25cf Practice deep breathing and relaxation techniques",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 4
  },
  {
    "heading": "Progression Tips",
    "content": "Progression Tips \n\u25cf Increase reps by 2\u20135 every week as strength improves \n\u25cf Reduce rest time between circuits by 10 seconds every two weeks \n\u25cf Add more rounds to your circuits (e.g., go from 4 to 5 rounds) by week 6\u20138 \n\u25cf For cardio, increase interval time or add more rounds gradually \nRecovery & Safety \n\u25cf Always warm up before and cool down after workouts \n\u25cf Listen to your body\u2014modify or skip exercises if you feel pain (sharp or unusual) \n\u25cf Stay hydrated and fuel your body with nutritious foods \n\u25cf Get at least 7-8 hours of sleep per night for optimal recovery \nMotivation & Consistency Tips \n\u25cf Set weekly goals and track your progress (e.g., reps, time, or how you feel) \n\u25cf Mix up your workouts occasionally to avoid boredom \n\u25cf Find a workout buddy or join an online community for accountability \n\u25cf Celebrate milestones with small non-food rewards (new workout gear, a hike, etc.) \nLab Exercise - 1 \n \nUsing GenAI tools, create a short story or poem (text generation) based on a chosen theme, \nthen generate an image (text-to-image generation) and a 15-30 second sound or music clip \n(AI sound generation) that represent the same theme, and analysing how well the text, \nimage and sound outputs align with each other while discussing the strengths, limitations \nand ethical challenges of multimodal genAI. \n \nChosen Theme - Nature \n \nPoem -   \n\ud83c\udf31 1. Short Poem (Text Generation) \n\u201cWhispers of Nature\u201d \nThe forest breathes a quiet song, \n Where rivers weave their silver thread. \n The wind lifts leaves and carries on, \n A gentle hymn where footsteps tread. \n\nThe sun spills gold through emerald skies, \n Mountains stand tall in timeless grace. \n In every bird, a secret lies\u2014 \n The earth reflects its warm embrace. \nImage - \n \n \n \n \n \nAnalysis - \nPerfect \u2014 now we have all three modalities: \n1. Text (Poem: \u201cWhispers of Nature\u201d) \n2. Image (Forest clearing at sunrise \u2014 Screenshot file) \n3. Sound (Untitled design.mp4 \u2014 your audio/musical clip) \nLet\u2019s analyze how they align and reflect the theme Nature, then discuss strengths, \nlimitations, and ethical challenges of multimodal GenAI. \n\ud83d\udd0e Alignment Analysis",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 6
  },
  {
    "heading": "1. Text (Poem)",
    "content": "1. Text (Poem) \n\u25cf Mood: Calm, reverent, lyrical. \n\u25cf Imagery: Forest, rivers, wind, birds, sunlight, mountains. \n\u25cf Theme: Harmony between humans and natural elements.",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 7
  },
  {
    "heading": "2. Image (Forest Clearing at Sunrise)",
    "content": "2. Image (Forest Clearing at Sunrise) \n\u25cf Mood: Peaceful, dreamlike. \n\u25cf Visuals: Golden light, emerald trees, silver water, distant mountains, birds in flight. \n\u25cf Theme: The same metaphors as the poem are literally painted into the scene. \n\n\u2705 Strong alignment: The golden sun, silver-threaded river, trees, and birds directly \nmirror the poem\u2019s imagery.",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 7
  },
  {
    "heading": "3. Sound (Music Clip)",
    "content": "3. Sound (Music Clip) \n\u25cf Mood: Likely tranquil, flowing, possibly minimalistic. \n\u25cf Theme: Music often conveys the same serenity and timeless grace present in the \npoem and image. \n\u2705 If the music is ambient and soothing, it completes the triad: words (imagination), image \n(visual reality), sound (emotional atmosphere). \n \n\ud83c\udf1f Strengths of Multimodal GenAI \n1. Immersive Storytelling: Combining text, visuals, and sound makes the theme more \npowerful than each medium alone. \n2. Accessibility: Different senses are engaged \u2014 readers, visual thinkers, and auditory \nlearners all benefit. \n3. Creativity Amplified: Even non-artists can create a poetic + visual + musical \nexperience. \n\u2696 Limitations \n1. Surface-level Alignment: Tools may match mood or keywords, but not always \ndeeper meaning (e.g., a forest image may look serene but miss the symbolic depth of \nthe poem). \n2. Quality Variability: Text may be nuanced, while images can be overly stylized or \nclich\u00e9, and sound may not perfectly sync in pacing. \n3. Context Gaps: Without human curation, multimodal outputs may feel disjointed \nrather than unified. \n\ud83d\udee1 Ethical Challenges \n1. Authorship & Ownership: Who owns a multimodal creation \u2014 the AI, the user, or \nthe original dataset contributors? \n2. Bias in Nature Representation: AI might default to Western, idealized landscapes \n(green forests, golden sunsets), neglecting deserts, tundras, or urban nature. \n3. Deepfake Concerns: Generated sounds or visuals could mislead if presented as \nauthentic recordings/photos. \n4. Environmental Paradox: Ironically, AI that celebrates \u201cNature\u201d consumes significant \nenergy/resources. \n\ud83d\udccc Conclusion \n\nThe poem, image, and sound together build a cohesive representation of Nature\u2019s \nserenity. The poem provides abstract emotional depth, the image grounds it in vivid reality, \nand the sound sustains the atmosphere. \n\u25cf Strengths: They harmonize well to deliver an immersive nature experience. \n \n\u25cf Limitations: Without careful human curation, alignment may remain at surface \nimagery rather than deep symbolic levels. \n \n\u25cf Ethical note: Responsible use requires transparency, acknowledgment of biases, \nand mindfulness of energy costs.",
    "pdf_name": "GenAI exercise 1.pdf",
    "page_number": 8
  }
]